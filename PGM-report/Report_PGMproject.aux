\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{cca1}
\citation{cca2}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {paragraph}{Abstract ---}{1}{section*.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Canonical correlation analysis}{1}{section.1.1}}
\@writefile{brf}{\backcite{cca1}{{1}{1.1}{section.1.1}}}
\newlabel{eq.eig1}{{1.1}{1}{Canonical correlation analysis}{equation.1.1.1}{}}
\citation{cca2}
\@writefile{brf}{\backcite{cca2}{{2}{1.1}{equation.1.1.1}}}
\@writefile{brf}{\backcite{cca2}{{2}{1.1}{equation.1.1.1}}}
\newlabel{eq.eig2}{{1.2}{2}{Canonical correlation analysis}{equation.1.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Preliminary tests on half-synthetic data}{2}{subsection.1.1.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:1-toy}{{1.1a}{3}{Canonical variates along the \textit {first two} directions; 'visual'.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:1-toy}{{a}{3}{Canonical variates along the \textit {first two} directions; 'visual'.\relax }{figure.caption.2}{}}
\newlabel{fig:1-toybis}{{1.1b}{3}{Canonical variates along the \textit {first two} directions; 'text'. \relax }{figure.caption.2}{}}
\newlabel{sub@fig:1-toybis}{{b}{3}{Canonical variates along the \textit {first two} directions; 'text'. \relax }{figure.caption.2}{}}
\newlabel{fig:1-toys}{{\caption@xref {fig:1-toys}{ on input line 187}}{3}{Preliminary tests on half-synthetic data}{figure.caption.2}{}}
\newlabel{fig:1-toy23}{{1.2a}{3}{Canonical variates along directions 2 and 3 : $W_m(:,2)\text { and } W_m(:,3)$; 'visual'.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:1-toy23}{{a}{3}{Canonical variates along directions 2 and 3 : $W_m(:,2)\text { and } W_m(:,3)$; 'visual'.\relax }{figure.caption.3}{}}
\newlabel{fig:1-toybis23}{{1.2b}{3}{Canonical variates along directions 2 and 3 : $W_m(:,2)\text { and } W_m(:,3)$; 'text'. \relax }{figure.caption.3}{}}
\newlabel{sub@fig:1-toybis23}{{b}{3}{Canonical variates along directions 2 and 3 : $W_m(:,2)\text { and } W_m(:,3)$; 'text'. \relax }{figure.caption.3}{}}
\newlabel{fig:1-toys23}{{\caption@xref {fig:1-toys23}{ on input line 203}}{3}{Preliminary tests on half-synthetic data}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Dataset: INRIA-webqueries}{3}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Visual feature}{4}{subsection.1.2.1}}
\newlabel{fig:1-toy23}{{\caption@xref {fig:1-toy23}{ on input line 228}}{4}{Visual feature}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces For the text features, only text between (<ptitle>, </ptitle>), (<before>, </before>) and ((<after>, </after>)) are extracted.\relax }}{4}{figure.caption.4}}
\newlabel{fig:inria-dataset}{{1.3}{4}{For the text features, only text between (<ptitle>, </ptitle>), (<before>, </before>) and ((<after>, </after>)) are extracted.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Textual feature}{4}{subsection.1.2.2}}
\citation{cca0}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Training and test}{5}{section.1.3}}
\newlabel{fig:1-real23}{{1.4a}{5}{Canonical variates along directions 1 and 2:\\$W_m(:,1)\text { and } W_m(:,2)$; 'visual'.\relax }{figure.caption.5}{}}
\newlabel{sub@fig:1-real23}{{a}{5}{Canonical variates along directions 1 and 2:\\$W_m(:,1)\text { and } W_m(:,2)$; 'visual'.\relax }{figure.caption.5}{}}
\newlabel{fig:1-real23}{{1.4b}{5}{Canonical variates along directions 1 and 2:\\ $W_m(:,1)\text { and } W_m(:,2)$; 'text'. \relax }{figure.caption.5}{}}
\newlabel{sub@fig:1-real23}{{b}{5}{Canonical variates along directions 1 and 2:\\ $W_m(:,1)\text { and } W_m(:,2)$; 'text'. \relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces We notice that the projected points of \textit  {arc de triomphe} and \textit  {brandenburg gate} are difficult to be distinguished in the 'visual' view and that is easier in the 'textual' view. In both views, the clusters of \textit  {arc de triomphe} and \textit  {iphone} have two different directions.\relax }}{5}{figure.caption.5}}
\newlabel{fig:1-reall23}{{1.4}{5}{We notice that the projected points of \textit {arc de triomphe} and \textit {brandenburg gate} are difficult to be distinguished in the 'visual' view and that is easier in the 'textual' view. In both views, the clusters of \textit {arc de triomphe} and \textit {iphone} have two different directions.\relax }{figure.caption.5}{}}
\@writefile{brf}{\backcite{cca0}{{6}{1.3}{figure.caption.5}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Image-to-text search on test data}{6}{subsection.1.3.1}}
\newlabel{fig:1-arc1}{{\caption@xref {fig:1-arc1}{ on input line 284}}{6}{Image-to-text search on test data}{figure.caption.6}{}}
\newlabel{fig:inria-dataset}{{\caption@xref {fig:inria-dataset}{ on input line 286}}{6}{Image-to-text search on test data}{figure.caption.6}{}}
\newlabel{fig:1-arc1}{{\caption@xref {fig:1-arc1}{ on input line 294}}{6}{Image-to-text search on test data}{figure.caption.7}{}}
\newlabel{fig:inria-dataset}{{\caption@xref {fig:inria-dataset}{ on input line 296}}{6}{Image-to-text search on test data}{figure.caption.7}{}}
\newlabel{fig:1-arc1}{{\caption@xref {fig:1-arc1}{ on input line 304}}{6}{Image-to-text search on test data}{figure.caption.8}{}}
\newlabel{fig:inria-dataset}{{\caption@xref {fig:inria-dataset}{ on input line 306}}{6}{Image-to-text search on test data}{figure.caption.8}{}}
\newlabel{fig:monts1}{{\caption@xref {fig:monts1}{ on input line 314}}{6}{Image-to-text search on test data}{figure.caption.9}{}}
\newlabel{fig:i2t}{{\caption@xref {fig:i2t}{ on input line 316}}{6}{Image-to-text search on test data}{figure.caption.9}{}}
\newlabel{fig:1-arc1}{{\caption@xref {fig:1-arc1}{ on input line 325}}{7}{Image-to-text search on test data}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Five examples of image-to-text search on test data: the words correspond to the trained text vectors that have the highest similarities with the test image's visual feature; the scores is the count of occurrences of such each word.\relax }}{7}{figure.caption.10}}
\newlabel{fig:i2t}{{1.5}{7}{Five examples of image-to-text search on test data: the words correspond to the trained text vectors that have the highest similarities with the test image's visual feature; the scores is the count of occurrences of such each word.\relax }{figure.caption.10}{}}
\newlabel{fig:i2iappler}{{\caption@xref {fig:i2iappler}{ on input line 341}}{7}{Image-to-text search on test data}{figure.caption.11}{}}
\newlabel{fig:inria-dataset}{{\caption@xref {fig:inria-dataset}{ on input line 343}}{7}{Image-to-text search on test data}{figure.caption.11}{}}
\newlabel{fig:i2iapple1}{{\caption@xref {fig:i2iapple1}{ on input line 351}}{7}{Image-to-text search on test data}{figure.caption.12}{}}
\newlabel{fig:inria-dataset}{{\caption@xref {fig:inria-dataset}{ on input line 353}}{7}{Image-to-text search on test data}{figure.caption.12}{}}
\newlabel{fig:i2iappler}{{\caption@xref {fig:i2iappler}{ on input line 361}}{8}{Image-to-text search on test data}{figure.caption.13}{}}
\newlabel{fig:inria-dataset}{{\caption@xref {fig:inria-dataset}{ on input line 363}}{8}{Image-to-text search on test data}{figure.caption.13}{}}
\newlabel{fig:i2iapple1}{{\caption@xref {fig:i2iapple1}{ on input line 371}}{8}{Image-to-text search on test data}{figure.caption.14}{}}
\newlabel{fig:inria-dataset}{{\caption@xref {fig:inria-dataset}{ on input line 373}}{8}{Image-to-text search on test data}{figure.caption.14}{}}
\newlabel{fig:i2iappler}{{\caption@xref {fig:i2iappler}{ on input line 392}}{8}{Image-to-text search on test data}{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces \relax }}{8}{figure.caption.15}}
\newlabel{fig:inria-dataset}{{1.6}{8}{\relax }{figure.caption.15}{}}
\newlabel{fig:i2iapple1}{{\caption@xref {fig:i2iapple1}{ on input line 402}}{9}{Image-to-text search on test data}{figure.caption.16}{}}
\newlabel{fig:inria-dataset}{{\caption@xref {fig:inria-dataset}{ on input line 404}}{9}{Image-to-text search on test data}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Text-to-image search on test data}{9}{subsection.1.3.2}}
\newlabel{fig:1-metro}{{\caption@xref {fig:1-metro}{ on input line 429}}{10}{Text-to-image search on test data}{figure.caption.17}{}}
\newlabel{fig:inria-dataset}{{\caption@xref {fig:inria-dataset}{ on input line 431}}{10}{Text-to-image search on test data}{figure.caption.17}{}}
\bibstyle{agu04}
\bibdata{biblio}
\newlabel{fig:1-metro}{{\caption@xref {fig:1-metro}{ on input line 441}}{11}{Text-to-image search on test data}{figure.caption.18}{}}
\newlabel{fig:inria-dataset}{{\caption@xref {fig:inria-dataset}{ on input line 443}}{11}{Text-to-image search on test data}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Evaluations and conclusion}{11}{section.1.4}}
\bibcite{cca2}{{1}{2005}{{\textit  {Bach and Jordan}}}{{}}}
\bibcite{cca0}{{2}{2014}{{\textit  {Gong et~al.}}}{{\textit  {Gong, Ke, Isard, and Lazebnik}}}}
\bibcite{cca1}{{3}{2007}{{\textit  {Hardoon et~al.}}}{{\textit  {Hardoon, Szedmak, Szedmak, and Shawe-taylor}}}}
